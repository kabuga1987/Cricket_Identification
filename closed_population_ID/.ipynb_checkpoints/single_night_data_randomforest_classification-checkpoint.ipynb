{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ab4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca1069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6858309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData:\n",
    "    \n",
    "    \n",
    "    def __init__(self, path_csv, path_samples):\n",
    "        \n",
    "        self.path_csv = path_csv\n",
    "        self.n1_trn = path_samples + \"n1_train.csv\"\n",
    "        self.n1_val = path_samples + \"n1_validation.csv\"\n",
    "        self.n1_tst = path_samples + \"n1_test.csv\"\n",
    "        self.n2_tst = path_samples + \"n2_test.csv\"\n",
    "        self.n3_tst = path_samples + \"n3_test.csv\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def slice_data_frame(self, path):\n",
    "        \"\"\"Select Segment, and ID columns from a data frame\"\"\"\n",
    "        df = pd.read_csv(path)\n",
    "        return df[[\"Segment\", \"ID\"]]\n",
    "        \n",
    "    def sample_to_ID(self, df):\n",
    "        \"\"\"Map each sample to its ID given a data frame of samples and IDs\"\"\"\n",
    "        return dict([(sample, ID) for sample, ID in df.to_records(index = False)])\n",
    "    \n",
    "    def ID_to_samples(self, sample_2_ID_dict):\n",
    "        \"\"\"Group samples per ID\"\"\"\n",
    "        ID_2_samples = {}\n",
    "        for sample, ID in sample_2_ID_dict.items():\n",
    "            if ID not in ID_2_samples:ID_2_samples[ID] = [sample]\n",
    "            else:ID_2_samples[ID].append(sample)\n",
    "        return ID_2_samples\n",
    "    \n",
    "        \n",
    "    def get_samples_labels(self, lst_samples, ID_2_samples_dict):\n",
    "        samp_2_numericID = dict([(a[j], i) for i, a in enumerate(ID_2_samples_dict.values()) for j in range(len(a))])\n",
    "        samples, labels = zip(*[(sample, samp_2_numericID[sample]) for sample in lst_samples])\n",
    "        return np.array(samples), np.array(labels)\n",
    "    \n",
    "    def get_samples(self, path): return pd.read_csv(path).Segment.values\n",
    "        \n",
    "    \n",
    "    def labelled_samples(self):\n",
    "        \n",
    "        df = self.slice_data_frame(self.path_csv)\n",
    "        sample_2_ID = self.sample_to_ID(df)\n",
    "        ID_2_samples = self.ID_to_samples(sample_2_ID)\n",
    "        \n",
    "        n1_trn_s = self.get_samples(self.n1_trn)\n",
    "        n1_val_s = self.get_samples(self.n1_val)\n",
    "        n1_tst_s = self.get_samples(self.n1_tst)\n",
    "        n2_tst_s = self.get_samples(self.n2_tst)\n",
    "        n3_tst_s = self.get_samples(self.n3_tst)\n",
    "        \n",
    "        n1ts, n1ty = self.get_samples_labels(n1_trn_s, ID_2_samples)\n",
    "        n1vs, n1vy = self.get_samples_labels(n1_val_s, ID_2_samples)\n",
    "        n1es, n1ey = self.get_samples_labels(n1_tst_s, ID_2_samples)\n",
    "        n2es, n2ey = self.get_samples_labels(n2_tst_s, ID_2_samples)\n",
    "        n2es, n2ey = self.get_samples_labels(n2_tst_s, ID_2_samples)\n",
    "        n3es, n3ey = self.get_samples_labels(n3_tst_s, ID_2_samples)\n",
    "        \n",
    "        t1 = np.arange(len(n1_trn_s))\n",
    "        v1 = np.arange(len(n1_val_s))\n",
    "        e1 = np.arange(len(n1_tst_s))\n",
    "        t2 = np.arange(len(n2_tst_s))\n",
    "        t3 = np.arange(len(n3_tst_s))\n",
    "\n",
    "        np.random.shuffle(t1)\n",
    "        np.random.shuffle(v1)\n",
    "        np.random.shuffle(e1)\n",
    "        np.random.shuffle(t2)\n",
    "        np.random.shuffle(t3)\n",
    "        \n",
    "        return n1ts[t1], n1ty[t1], n1vs[v1], n1vy[v1], n1es[e1], n1ey[e1], n2es[t2], n2ey[t2], n3es[t3], n3ey[t3]\n",
    "    \n",
    "class RFClassifier(SampleData):\n",
    "    \n",
    "    def __init__(self,p_mfccs, p_predictions, p_seg_chrs, p_samples):\n",
    "        self.p_mfccs = p_mfccs\n",
    "        self.p_predictions = p_predictions\n",
    "        self.p_seg_chrs  = p_seg_chrs\n",
    "        self.p_samples = p_samples\n",
    "        super().__init__(self.p_seg_chrs, self.p_samples)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sample_to_mfccs(self, path):\n",
    "        mfccs_df = pd.read_csv(path)\n",
    "        rows = [row.values for _, row in mfccs_df.iterrows()]\n",
    "        sample_2_mfccs = {row[0]:row[1:] for row in rows}\n",
    "        return sample_2_mfccs\n",
    "    \n",
    "    def lst_samples_to_mfccs(self, lst_samples, lst_labels, sample_2_mfccs_dict):\n",
    "        sams, mfccs = zip(*[(lst_samples[i],sample_2_mfccs_dict[lst_samples[i]]) for i in range(len(lst_samples))])\n",
    "        sam2lab = {\"samples\":sams, \"labels\":lst_labels}\n",
    "        df = pd.DataFrame(sam2lab)\n",
    "        return df, lst_labels, np.array(mfccs)\n",
    "    \n",
    "    def random_forest_model(self, samp_2_mfccs_dict, lst_samples, lst_labels):\n",
    "    \n",
    "        _, t_y, t_fs = self.lst_samples_to_mfccs(lst_samples,  lst_labels, samp_2_mfccs_dict)\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators = 1000,\n",
    "                                    max_features = 5\n",
    "        )\n",
    "        rf.fit(t_fs, t_y)\n",
    "        \n",
    "        return rf\n",
    "    \n",
    "#     def random_forest_model(self, samp_2_mfccs_dict, lst_samples, lst_labels):\n",
    "    \n",
    "#         _, t_y, t_fs = self.lst_samples_to_mfccs(lst_samples,  lst_labels, samp_2_mfccs_dict)\n",
    "        \n",
    "#         rf = RandomForestClassifier()\n",
    "        \n",
    "#         parameter_grid = {\"n_estimators\":[100, 200, 500, 1000],\n",
    "#                  \"max_features\":[6,7,8,10],\n",
    "#                  \"max_depth\":[1,2,5,20]}\n",
    "        \n",
    "#         grid_search = GridSearchCV(estimator = rf, param_grid = parameter_grid, cv = 3)\n",
    "        \n",
    "#         grid_search.fit(t_fs, t_y)\n",
    "#         print(\"best parameters are: \", grid_search.best_params_)\n",
    "#         best_pars = grid_search.best_params_\n",
    "#         np.save(\"best_parameters.npy\",best_pars)\n",
    "        \n",
    "#         return grid_search.best_estimator_\n",
    "    \n",
    "    def predict(self,  model, lst_samples, lst_labels, samp_2_mfcc_dict, night = None):\n",
    "        df, y, fs = self.lst_samples_to_mfccs(lst_samples, lst_labels, samp_2_mfcc_dict)\n",
    "        p = model.predict(fs)\n",
    "        accuracy = np.where(y == p)[0].shape[0]/y.shape[0]\n",
    "        df[\"predictions\"] = p\n",
    "        df.to_csv(self.p_predictions + night + \".csv\", index  = False)\n",
    "        return accuracy\n",
    "    \n",
    "    def execution(self):\n",
    "        \n",
    "        sample_2_mfccs = self.sample_to_mfccs(self.p_mfccs)\n",
    "        Ts, Ty, Vs, Vy, N1s, N1y, N2s, N2y, N3s, N3y = super().labelled_samples()\n",
    "        rf = self.random_forest_model(sample_2_mfccs, Ts, Ty)\n",
    "        a1v = self.predict(rf, Vs, Vy, sample_2_mfccs, \"single_night_data_night1v\")\n",
    "        a1 = self.predict(rf, N1s, N1y, sample_2_mfccs,  \"single_night_data_night1\")\n",
    "        a2 = self.predict(rf, N2s, N2y, sample_2_mfccs,  \"single_night_data_night2\")\n",
    "        a3 = self.predict(rf, N3s, N3y, sample_2_mfccs,  \"single_night_data_night3\")\n",
    "        \n",
    "        a = {\"accuracy\":[a1v, a1,a2,a3]}\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(a, orient = \"index\", columns = [\"night1v\", \"night1\", \"night2\", \"night3\"])\n",
    "        df = df.rename_axis(\"accuracy\")\n",
    "        df.to_csv(self.p_predictions + \"single_night_data_accuracy.csv\")\n",
    "        return df\n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02de41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf9b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"1_s_mfccs.csv\"\n",
    "#p1 = \"1_s_f_MFCCs.csv\"\n",
    "p2 = \"classification_predictions/rf/\"\n",
    "p3 = \"segment_2_characts.cvs\"\n",
    "p4 = \"all_tr_val_tst/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660484e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1973e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RFClassifier(p1, p2, p3, p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d41f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = RFC.execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5367c44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>night1v</th>\n",
       "      <th>night1</th>\n",
       "      <th>night2</th>\n",
       "      <th>night3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>0.194693</td>\n",
       "      <td>0.193597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           night1v    night1    night2    night3\n",
       "accuracy                                        \n",
       "accuracy  0.987327  0.987018  0.194693  0.193597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f89b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = np.load(\"best_parameters.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216deed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df745bcd",
   "metadata": {},
   "source": [
    "The usual parameters for random forests are: number of trees (n_estimators), number of attributes that are randomly selected for the split search when constructing each tree (max_features), and limits on the tree depth for each tree (max_depth). The higher the number of tree the greater the performance. The number of features to select is by default the square root of the number of atributes (for classification). The randomForest package, controls the depth by the minimum number of cases to perform a split in the tree construction algorithm, and for classification they suggest 1, that is no constraints on the depth of the tree. Sklearn uses 2 as this min_samples_split. If you plan to search this hyperparameter, I think it is wiser to control the minimum number of samples to split the tree, and 1, 2 or 5 seems reasonable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\"n_estimators\":[100, 200, 500, 1000],\n",
    "                 \"max_features\":[6,7,8,10],\n",
    "                 \"max_detph\":[1,2,5,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de490d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rf, param_grid = parameter_grid, cv = 3)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "grid_search.best_params_\n",
    "best_grid = grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
