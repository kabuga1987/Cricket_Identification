{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ab4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fca1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_helper import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6858309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    \n",
    "    \n",
    "    def __init__(self, path_csv, path_samples):\n",
    "        \n",
    "        self.path_csv = path_csv\n",
    "        self.n1_trn = path_samples + \"n1_train.csv\"\n",
    "        self.n1_val = path_samples + \"n1_validation.csv\"\n",
    "        self.n1_tst = path_samples + \"n1_test.csv\"\n",
    "        self.n2_tst = path_samples + \"n2_test.csv\"\n",
    "        self.n3_tst = path_samples + \"n3_test.csv\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def slice_data_frame(self, path):\n",
    "        \"\"\"Select Segment, and ID columns from a data frame\"\"\"\n",
    "        df = pd.read_csv(path)\n",
    "        return df[[\"Segment\", \"ID\"]]\n",
    "        \n",
    "    def sample_to_ID(self, df):\n",
    "        \"\"\"Map each sample to its ID given a data frame of samples and IDs\"\"\"\n",
    "        return dict([(sample, ID) for sample, ID in df.to_records(index = False)])\n",
    "    \n",
    "    def ID_to_samples(self, sample_2_ID_dict):\n",
    "        \"\"\"Group samples per ID\"\"\"\n",
    "        ID_2_samples = {}\n",
    "        for sample, ID in sample_2_ID_dict.items():\n",
    "            if ID not in ID_2_samples:ID_2_samples[ID] = [sample]\n",
    "            else:ID_2_samples[ID].append(sample)\n",
    "        return ID_2_samples\n",
    "    \n",
    "        \n",
    "    def hot_encod_labels(self, lst_samples, ID_2_samples_dict):\n",
    "        samp_2_numericID = dict([(a[j], i) for i, a in enumerate(ID_2_samples_dict.values()) for j in range(len(a))])\n",
    "        samples, IDs = zip(*[(samp, ID) for samp,ID in samp_2_numericID.items()])\n",
    "        IDs = to_categorical(IDs)\n",
    "        sample_2_ID = {samples[i]:IDs[i] for i in range(len(samples))}\n",
    "        samples, labels = zip(*[(sample, sample_2_ID[sample]) for sample in lst_samples])\n",
    "        return np.array(samples), np.array(labels)\n",
    "    \n",
    "    def get_samples(self, path): return pd.read_csv(path).Segment.values\n",
    "        \n",
    "    \n",
    "    def HotEncodeLabels(self):\n",
    "        \n",
    "        df = self.slice_data_frame(self.path_csv)\n",
    "        sample_2_ID = self.sample_to_ID(df)\n",
    "        ID_2_samples = self.ID_to_samples(sample_2_ID)\n",
    "        \n",
    "        n1_trn_s = self.get_samples(self.n1_trn)\n",
    "        n1_val_s = self.get_samples(self.n1_val)\n",
    "        n1_tst_s = self.get_samples(self.n1_tst)\n",
    "        n2_tst_s = self.get_samples(self.n2_tst)\n",
    "        n3_tst_s = self.get_samples(self.n3_tst)\n",
    "        \n",
    "        n1ts, n1ty = self.hot_encod_labels(n1_trn_s, ID_2_samples)\n",
    "        n1vs, n1vy = self.hot_encod_labels(n1_val_s, ID_2_samples)\n",
    "        n1es, n1ey = self.hot_encod_labels(n1_tst_s, ID_2_samples)\n",
    "        n2es, n2ey = self.hot_encod_labels(n2_tst_s, ID_2_samples)\n",
    "        n2es, n2ey = self.hot_encod_labels(n2_tst_s, ID_2_samples)\n",
    "        n3es, n3ey = self.hot_encod_labels(n3_tst_s, ID_2_samples)\n",
    "        \n",
    "        t1 = np.arange(len(n1_trn_s))\n",
    "        v1 = np.arange(len(n1_val_s))\n",
    "        e1 = np.arange(len(n1_tst_s))\n",
    "        t2 = np.arange(len(n2_tst_s))\n",
    "        t3 = np.arange(len(n3_tst_s))\n",
    "\n",
    "        np.random.shuffle(t1)\n",
    "        np.random.shuffle(v1)\n",
    "        np.random.shuffle(e1)\n",
    "        np.random.shuffle(t2)\n",
    "        np.random.shuffle(t3)\n",
    "        \n",
    "        return n1ts[t1], n1ty[t1], n1vs[v1], n1vy[v1], n1es[e1], n1ey[e1], n2es[t2], n2ey[t2], n3es[t3], n3ey[t3]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0e334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    \n",
    "    def __init__(self, model,v1x, v1y, n1x, n1y, n2x, n2y, n3x, n3y,vgen, gen1, gen2, gen3, p_preds):\n",
    "        self.model = model\n",
    "        self.v1x = v1x\n",
    "        self.v1y = v1y\n",
    "        self.n1x = n1x\n",
    "        self.n1y = n1y\n",
    "        self.n2x = n2x\n",
    "        self.n2y = n2y\n",
    "        self.n3x = n3x\n",
    "        self.n3y = n3y\n",
    "        self.vgen = vgen\n",
    "        self.gen1 = gen1\n",
    "        self.gen2 = gen2\n",
    "        self.gen3 = gen3\n",
    "        self.p_preds = p_preds\n",
    "        \n",
    "        \n",
    "    def predict(self, model, samples, hotlabels, generator, night, verbose):\n",
    "        predictions = model.predict(generator, verbose = verbose)\n",
    "        observed = np.argmax(hotlabels, axis = 1)\n",
    "        predicted = np.argmax(predictions, axis = 1)\n",
    "        accuracy = np.where(observed == predicted)[0].shape[0]/observed.shape[0]\n",
    "        print(f\"accuracy for {night} = \", accuracy)\n",
    "        data = {\"samples\": samples, \"labels\": observed, \"predictions\": predicted}\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(self.p_preds + night + \".csv\")\n",
    "        return accuracy\n",
    "    \n",
    "    def execution(self):\n",
    "        av = self.predict(self.model, self.v1x, self.v1y, self.vgen,\"one_n1_val\", 0)\n",
    "        av = round(av, ndigits = 3)\n",
    "        print()\n",
    "        a1 = self.predict(self.model, self.n1x, self.n1y, self.gen1,\"one_n1_test\", 0 )\n",
    "        a1 = round(a1, ndigits = 3)         \n",
    "        print()\n",
    "        a2 = self.predict(self.model, self.n2x, self.n2y, self.gen2,\"one_n2_test\", 0 )\n",
    "        a2 = round(a2, ndigits = 3)\n",
    "        print()\n",
    "        a3 = self.predict(self.model, self.n3x, self.n3y, self.gen3,\"one_n3_test\", 0 )\n",
    "        a3 = round(a3, ndigits = 3)\n",
    "        \n",
    "        a = {\"accuracy\":[av, a1,a2,a3]}\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(a, orient = \"index\", columns = [\"night1v\",\"night1\", \"night2\", \"night3\"])\n",
    "        df = df.rename_axis(\"accuracy\")\n",
    "        df.to_csv(self.p_preds + \"one_clas_metrics.csv\")\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72fe13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2af96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c58e355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "Training model has started\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Epoch 1/30\n",
      "122/122 [==============================] - 102s 780ms/step - loss: 1.9615 - accuracy: 0.4866 - val_loss: 4.8504 - val_accuracy: 0.0407 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "122/122 [==============================] - 80s 654ms/step - loss: 0.2384 - accuracy: 0.9291 - val_loss: 6.5247 - val_accuracy: 0.0422 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "122/122 [==============================] - 80s 655ms/step - loss: 0.1165 - accuracy: 0.9657 - val_loss: 5.4190 - val_accuracy: 0.1962 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "122/122 [==============================] - 81s 656ms/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.4829 - val_accuracy: 0.8587 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "122/122 [==============================] - 80s 649ms/step - loss: 0.0716 - accuracy: 0.9786 - val_loss: 0.2163 - val_accuracy: 0.9414 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "122/122 [==============================] - 81s 658ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.0974 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "122/122 [==============================] - 79s 642ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.1525 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "122/122 [==============================] - 80s 650ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.1703 - val_accuracy: 0.9507 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "122/122 [==============================] - 80s 648ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.1428 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "122/122 [==============================] - 80s 647ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.5656 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "122/122 [==============================] - 79s 646ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.1158 - val_accuracy: 0.9693 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "122/122 [==============================] - 81s 658ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0153 - val_accuracy: 0.9954 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "122/122 [==============================] - 80s 653ms/step - loss: 2.9177e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9956 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "122/122 [==============================] - 80s 654ms/step - loss: 1.7547e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9958 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "122/122 [==============================] - 81s 663ms/step - loss: 1.3429e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9962 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "122/122 [==============================] - 80s 653ms/step - loss: 1.0865e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9962 - lr: 5.0000e-04\n",
      "Epoch 17/30\n",
      "122/122 [==============================] - 80s 652ms/step - loss: 9.0571e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9962 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "122/122 [==============================] - 79s 644ms/step - loss: 7.7259e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9962 - lr: 5.0000e-04\n",
      "Epoch 19/30\n",
      "122/122 [==============================] - 79s 646ms/step - loss: 6.6804e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9964 - lr: 5.0000e-04\n",
      "Epoch 20/30\n",
      "122/122 [==============================] - 81s 658ms/step - loss: 5.8441e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9964 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "122/122 [==============================] - 80s 651ms/step - loss: 5.1618e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9965 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "122/122 [==============================] - 81s 660ms/step - loss: 4.5966e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9964 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "122/122 [==============================] - 81s 652ms/step - loss: 4.1117e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9964 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "122/122 [==============================] - 80s 648ms/step - loss: 3.6961e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "122/122 [==============================] - 81s 655ms/step - loss: 3.3404e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "122/122 [==============================] - ETA: 0s - loss: 3.0290e-05 - accuracy: 1.0000\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "122/122 [==============================] - 80s 650ms/step - loss: 3.0290e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9965 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "122/122 [==============================] - 79s 642ms/step - loss: 2.8010e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 28/30\n",
      "122/122 [==============================] - 80s 646ms/step - loss: 2.6710e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 29/30\n",
      "122/122 [==============================] - 80s 652ms/step - loss: 2.5457e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 30/30\n",
      "122/122 [==============================] - 79s 640ms/step - loss: 2.4247e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 2.5000e-04\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "accuracy for one_n1_val =  0.9965437788018433\n",
      "\n",
      "accuracy for one_n1_test =  0.9950362733867889\n",
      "\n",
      "accuracy for one_n2_test =  0.3016759776536313\n",
      "\n",
      "accuracy for one_n3_test =  0.3711864406779661\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    p1 = \"../segment_index_extraction/segment_data.csv\"\n",
    "    p2 = \"train_val_test_segment_data/\"\n",
    "    p3 = \"classification_predictions/cnn/\"\n",
    "     \n",
    "    PATH_ARRAY = \"arrays/\"\n",
    "    PATH_W = \"weights/n1_class.h5\"\n",
    "    SHP = (128,173,1)\n",
    "    \n",
    "    LR = 1e-3\n",
    "    lr = 1e-4\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 128\n",
    "    meanvar = True\n",
    "    \n",
    "    \n",
    "    encoder = LabelEncoder(p1,p2)\n",
    "    TIms,TLabs, VIms, VLabs, TeIms, TeLabs, N2Ims, N2Labs, N3Ims, N3Labs =  encoder.HotEncodeLabels()\n",
    "   \n",
    "    \n",
    "    Tgen = Generator(TIms, TLabs, SHP, BATCH_SIZE, PATH_ARRAY, meanvar)\n",
    "    Vgen = Generator(VIms, VLabs, SHP, BATCH_SIZE, PATH_ARRAY, meanvar)\n",
    "    Tegen = Generator(TeIms, TeLabs, SHP, BATCH_SIZE, PATH_ARRAY, meanvar)\n",
    "    n2gen = Generator(N2Ims, N2Labs, SHP, BATCH_SIZE, PATH_ARRAY, meanvar)\n",
    "    n3gen = Generator(N3Ims, N3Labs, SHP, BATCH_SIZE, PATH_ARRAY, meanvar)\n",
    "    \n",
    "   \n",
    "    architecture = ModelArchitecture(SHP)\n",
    "    trainer = Training()\n",
    "    trainer.architecture = architecture\n",
    "    \n",
    "    trainer.Tgenerator = Tgen\n",
    "    trainer.Vgenerator = Vgen\n",
    "\n",
    "    \n",
    "    \n",
    "    model = trainer.train(LR, lr, PATH_W, EPOCHS)\n",
    "    \n",
    "    predictor = Predictions(model,VIms,VLabs,TeIms,TeLabs,N2Ims,N2Labs,N3Ims,N3Labs,Vgen,Tegen,n2gen,n3gen, p3)\n",
    "    \n",
    "    \n",
    "    predictor.execution()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b366a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7d0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da9951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3213dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
